{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnOOSFZL2sD/06QCm5WGIX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Ikhwan-Fathulloh/Generative-Adversarial-Network-GAN/blob/main/avb_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH_kYYmPM8rm",
        "outputId": "b1e91008-94e7-4d6c-bfba-29d1ee5d7098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter-0; ELBO: -0.6802; T_loss: -1.388\n",
            "Iter-1000; ELBO: 1.359; T_loss: -4.232\n",
            "Iter-2000; ELBO: 0.5327; T_loss: -2.327\n",
            "Iter-3000; ELBO: -0.2026; T_loss: -1.408\n",
            "Iter-4000; ELBO: -0.3201; T_loss: -1.356\n",
            "Iter-5000; ELBO: -0.6626; T_loss: -1.146\n",
            "Iter-6000; ELBO: -0.2099; T_loss: -1.627\n",
            "Iter-7000; ELBO: -1.105; T_loss: -0.8719\n",
            "Iter-8000; ELBO: -0.02747; T_loss: -1.683\n",
            "Iter-9000; ELBO: -0.3182; T_loss: -1.393\n",
            "Iter-10000; ELBO: -0.4565; T_loss: -1.299\n",
            "Iter-11000; ELBO: -11.99; T_loss: -0.001405\n",
            "Iter-12000; ELBO: -0.1754; T_loss: -1.362\n",
            "Iter-13000; ELBO: -0.3587; T_loss: -1.299\n",
            "Iter-14000; ELBO: -0.2247; T_loss: -1.367\n",
            "Iter-15000; ELBO: -0.7013; T_loss: -1.154\n",
            "Iter-16000; ELBO: -0.3266; T_loss: -1.399\n",
            "Iter-17000; ELBO: -0.3998; T_loss: -1.488\n",
            "Iter-18000; ELBO: -0.5714; T_loss: -1.162\n",
            "Iter-19000; ELBO: -0.4501; T_loss: -1.206\n",
            "Iter-20000; ELBO: -0.6838; T_loss: -1.192\n",
            "Iter-21000; ELBO: -0.5736; T_loss: -1.262\n",
            "Iter-22000; ELBO: -0.8184; T_loss: -1.164\n",
            "Iter-23000; ELBO: -1.064; T_loss: -0.8597\n",
            "Iter-24000; ELBO: -0.5343; T_loss: -1.113\n",
            "Iter-25000; ELBO: -1.741; T_loss: -1.333\n",
            "Iter-26000; ELBO: -0.65; T_loss: -1.456\n",
            "Iter-27000; ELBO: -0.6302; T_loss: -1.127\n",
            "Iter-28000; ELBO: -0.2913; T_loss: -1.288\n",
            "Iter-29000; ELBO: -0.4152; T_loss: -1.56\n",
            "Iter-30000; ELBO: -0.8683; T_loss: -1.44\n",
            "Iter-31000; ELBO: -0.5277; T_loss: -1.236\n",
            "Iter-32000; ELBO: -0.6046; T_loss: -1.128\n",
            "Iter-33000; ELBO: -0.2896; T_loss: -1.328\n",
            "Iter-34000; ELBO: -0.4553; T_loss: -1.277\n",
            "Iter-35000; ELBO: -0.1742; T_loss: -1.386\n",
            "Iter-36000; ELBO: -0.6791; T_loss: -1.092\n",
            "Iter-37000; ELBO: -0.495; T_loss: -1.547\n",
            "Iter-38000; ELBO: -0.2755; T_loss: -1.508\n",
            "Iter-39000; ELBO: -0.5567; T_loss: -1.193\n",
            "Iter-40000; ELBO: -0.1894; T_loss: -1.371\n",
            "Iter-41000; ELBO: -0.5965; T_loss: -1.223\n",
            "Iter-42000; ELBO: -0.618; T_loss: -1.204\n",
            "Iter-43000; ELBO: -0.2617; T_loss: -1.279\n",
            "Iter-44000; ELBO: -0.3032; T_loss: -1.576\n",
            "Iter-45000; ELBO: -0.509; T_loss: -1.38\n",
            "Iter-46000; ELBO: -0.7504; T_loss: -0.9904\n",
            "Iter-47000; ELBO: -0.4232; T_loss: -1.393\n",
            "Iter-48000; ELBO: -0.8966; T_loss: -1.172\n",
            "Iter-49000; ELBO: -0.3545; T_loss: -1.473\n",
            "Iter-50000; ELBO: -0.02282; T_loss: -1.632\n",
            "Iter-51000; ELBO: -0.375; T_loss: -1.309\n",
            "Iter-52000; ELBO: -0.5842; T_loss: -1.074\n",
            "Iter-53000; ELBO: -0.2667; T_loss: -1.382\n",
            "Iter-54000; ELBO: -0.3847; T_loss: -1.32\n",
            "Iter-55000; ELBO: -0.5593; T_loss: -1.313\n",
            "Iter-56000; ELBO: -0.5186; T_loss: -1.266\n",
            "Iter-57000; ELBO: -0.471; T_loss: -1.31\n",
            "Iter-58000; ELBO: -0.282; T_loss: -1.382\n",
            "Iter-59000; ELBO: -0.1756; T_loss: -1.412\n",
            "Iter-60000; ELBO: -0.3785; T_loss: -1.374\n",
            "Iter-61000; ELBO: -0.1567; T_loss: -1.393\n",
            "Iter-62000; ELBO: -0.6653; T_loss: -1.308\n",
            "Iter-63000; ELBO: -0.5006; T_loss: -1.201\n",
            "Iter-64000; ELBO: -0.5312; T_loss: -1.196\n",
            "Iter-65000; ELBO: -0.134; T_loss: -1.441\n",
            "Iter-66000; ELBO: -0.168; T_loss: -1.337\n",
            "Iter-67000; ELBO: -0.1585; T_loss: -1.384\n",
            "Iter-68000; ELBO: -0.4394; T_loss: -1.372\n",
            "Iter-69000; ELBO: -0.4604; T_loss: -1.379\n",
            "Iter-70000; ELBO: -0.2613; T_loss: -1.367\n",
            "Iter-71000; ELBO: -0.1492; T_loss: -1.421\n",
            "Iter-72000; ELBO: -0.1879; T_loss: -1.403\n",
            "Iter-73000; ELBO: -0.6532; T_loss: -1.274\n",
            "Iter-74000; ELBO: -0.2249; T_loss: -1.385\n",
            "Iter-75000; ELBO: -0.2193; T_loss: -1.386\n",
            "Iter-76000; ELBO: -0.2772; T_loss: -1.359\n",
            "Iter-77000; ELBO: -0.2279; T_loss: -1.387\n",
            "Iter-78000; ELBO: -0.2217; T_loss: -1.385\n",
            "Iter-79000; ELBO: -0.2099; T_loss: -1.333\n",
            "Iter-80000; ELBO: -0.2351; T_loss: -1.384\n",
            "Iter-81000; ELBO: -0.218; T_loss: -1.377\n",
            "Iter-82000; ELBO: -0.2168; T_loss: -1.363\n",
            "Iter-83000; ELBO: -0.2465; T_loss: -1.4\n",
            "Iter-84000; ELBO: -0.2228; T_loss: -1.376\n",
            "Iter-85000; ELBO: -0.2496; T_loss: -1.39\n",
            "Iter-86000; ELBO: -0.2568; T_loss: -1.405\n",
            "Iter-87000; ELBO: -0.2629; T_loss: -1.387\n",
            "Iter-88000; ELBO: -0.1615; T_loss: -1.444\n",
            "Iter-89000; ELBO: -0.187; T_loss: -1.411\n",
            "Iter-90000; ELBO: -0.2166; T_loss: -1.372\n",
            "Iter-91000; ELBO: -0.2199; T_loss: -1.36\n",
            "Iter-92000; ELBO: -0.3932; T_loss: -1.373\n",
            "Iter-93000; ELBO: -0.3618; T_loss: -1.362\n",
            "Iter-94000; ELBO: -0.2828; T_loss: -1.286\n",
            "Iter-95000; ELBO: -0.2326; T_loss: -1.385\n",
            "Iter-96000; ELBO: -0.2266; T_loss: -1.39\n",
            "Iter-97000; ELBO: -0.2011; T_loss: -1.384\n",
            "Iter-98000; ELBO: -0.2207; T_loss: -1.386\n",
            "Iter-99000; ELBO: -0.1887; T_loss: -1.385\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Normalize the data to [0, 1] range\n",
        "mnist.data = mnist.data.float() / 255.0\n",
        "\n",
        "# Parameters\n",
        "mb_size = 32\n",
        "z_dim = 5\n",
        "X_dim = mnist.data.size(1) * mnist.data.size(2)  # Flattened image dimensions\n",
        "h_dim = 128\n",
        "lr = 1e-3\n",
        "\n",
        "# Create noise dimension\n",
        "eps_dim = 10  # Dimension of the noise vector\n",
        "\n",
        "# Encoder: q(z|x,eps)\n",
        "Q = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + eps_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, z_dim)\n",
        ")\n",
        "\n",
        "# Decoder: p(x|z)\n",
        "P = torch.nn.Sequential(\n",
        "    torch.nn.Linear(z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, X_dim),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Discriminator: T(X, z)\n",
        "T = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, 1)\n",
        ")\n",
        "\n",
        "def reset_grad():\n",
        "    Q.zero_grad()\n",
        "    P.zero_grad()\n",
        "    T.zero_grad()\n",
        "\n",
        "\n",
        "def sample_X(size):\n",
        "    indices = np.random.randint(0, len(mnist), size)\n",
        "    X = mnist.data[indices].view(size, -1).float()\n",
        "    return Variable(X)\n",
        "\n",
        "\n",
        "# Optimizers\n",
        "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
        "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
        "T_solver = optim.Adam(T.parameters(), lr=lr)\n",
        "\n",
        "# Initialize counter\n",
        "cnt = 0\n",
        "\"\"\"1000000\"\"\"\n",
        "\n",
        "# Your training loop goes here\n",
        "for it in range(100000):\n",
        "    X = sample_X(mb_size)\n",
        "    eps = Variable(torch.randn(mb_size, eps_dim))\n",
        "    z = Variable(torch.randn(mb_size, z_dim))\n",
        "\n",
        "    # Optimize VAE\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    X_sample = P(z_sample)\n",
        "    T_sample = T(torch.cat([X, z_sample], 1))\n",
        "\n",
        "    disc = torch.mean(-T_sample)\n",
        "    loglike = -nn.BCELoss()(X_sample, X) # Use BCELoss for binary cross-entropy\n",
        "\n",
        "    elbo = -(disc + loglike)\n",
        "\n",
        "    elbo.backward()\n",
        "    Q_solver.step()\n",
        "    P_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Discriminator T(X, z)\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    T_q = nn.Sigmoid()(T(torch.cat([X, z_sample], 1)))\n",
        "    T_prior = nn.Sigmoid()(T(torch.cat([X, z], 1)))\n",
        "\n",
        "    T_loss = -torch.mean(torch.log(T_q) + torch.log(1. - T_prior))\n",
        "\n",
        "    T_loss.backward()\n",
        "    T_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter-{}; ELBO: {:.4}; T_loss: {:.4}'\n",
        "              .format(it, -elbo.item(), -T_loss.item()))\n",
        "\n",
        "        samples = P(z).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'\n",
        "                    .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "        cnt += 1\n",
        "        plt.close(fig)"
      ]
    }
  ]
}