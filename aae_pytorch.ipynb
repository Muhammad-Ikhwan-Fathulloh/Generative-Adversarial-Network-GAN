{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOblf+70WZhYG0UBnjINC4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Ikhwan-Fathulloh/Generative-Adversarial-Network-GAN/blob/main/aae_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Normalize the data to [0, 1] range\n",
        "mnist.data = mnist.data.float() / 255.0\n",
        "\n",
        "# Parameters\n",
        "mb_size = 32\n",
        "z_dim = 5\n",
        "X_dim = mnist.data.size(1) * mnist.data.size(2)  # Flattened image dimensions\n",
        "h_dim = 128\n",
        "lr = 1e-3\n",
        "\n",
        "# Encoder\n",
        "Q = nn.Sequential(\n",
        "    nn.Linear(X_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, z_dim)\n",
        ")\n",
        "\n",
        "# Decoder\n",
        "P = nn.Sequential(\n",
        "    nn.Linear(z_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, X_dim),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Linear(z_dim, h_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(h_dim, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "def reset_grad():\n",
        "    Q.zero_grad()\n",
        "    P.zero_grad()\n",
        "    D.zero_grad()\n",
        "\n",
        "def sample_X(size):\n",
        "    indices = np.random.randint(0, len(mnist), size)\n",
        "    X = mnist.data[indices].view(size, -1).float()\n",
        "    return Variable(X)\n",
        "\n",
        "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
        "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
        "D_solver = optim.Adam(D.parameters(), lr=lr)\n",
        "\n",
        "\"\"\"1000000\"\"\"\n",
        "for it in range(10000):\n",
        "    X = sample_X(mb_size)\n",
        "\n",
        "    \"\"\" Reconstruction phase \"\"\"\n",
        "    z_sample = Q(X)\n",
        "    X_sample = P(z_sample)\n",
        "\n",
        "    # Clip values to be within [0, 1]\n",
        "    X_sample = X_sample.clamp(0, 1)\n",
        "\n",
        "    # Use BCELoss for binary cross entropy\n",
        "    recon_loss = nn.BCELoss()(X_sample, X)\n",
        "\n",
        "    recon_loss.backward()\n",
        "    P_solver.step()\n",
        "    Q_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    \"\"\" Regularization phase \"\"\"\n",
        "    # Discriminator\n",
        "    z_real = Variable(torch.randn(mb_size, z_dim))\n",
        "    z_fake = Q(X)\n",
        "\n",
        "    D_real = D(z_real)\n",
        "    D_fake = D(z_fake)\n",
        "\n",
        "    D_loss = -torch.mean(torch.log(D_real) + torch.log(1 - D_fake))\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Generator\n",
        "    z_fake = Q(X)\n",
        "    D_fake = D(z_fake)\n",
        "\n",
        "    G_loss = -torch.mean(torch.log(D_fake))\n",
        "\n",
        "    G_loss.backward()\n",
        "    Q_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter-{}; D_loss: {:.4}; G_loss: {:.4}; recon_loss: {:.4}'\n",
        "              .format(it, D_loss.item(), G_loss.item(), recon_loss.item()))\n",
        "\n",
        "        samples = P(z_real).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'\n",
        "                    .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "        cnt += 1\n",
        "        plt.close(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rbeetERQ76X",
        "outputId": "c766cfb7-0620-48a6-ac15-ee524994fa91"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter-0; D_loss: 1.417; G_loss: 0.6542; recon_loss: 0.6952\n",
            "Iter-1000; D_loss: 1.423; G_loss: 0.7065; recon_loss: 0.2693\n",
            "Iter-2000; D_loss: 1.5; G_loss: 0.5522; recon_loss: 0.2584\n",
            "Iter-3000; D_loss: 1.388; G_loss: 0.7931; recon_loss: 0.2247\n",
            "Iter-4000; D_loss: 1.439; G_loss: 0.6323; recon_loss: 0.1967\n",
            "Iter-5000; D_loss: 1.403; G_loss: 0.6942; recon_loss: 0.1886\n",
            "Iter-6000; D_loss: 1.379; G_loss: 0.7051; recon_loss: 0.188\n",
            "Iter-7000; D_loss: 1.384; G_loss: 0.6985; recon_loss: 0.1765\n",
            "Iter-8000; D_loss: 1.396; G_loss: 0.696; recon_loss: 0.1799\n",
            "Iter-9000; D_loss: 1.394; G_loss: 0.6977; recon_loss: 0.1732\n"
          ]
        }
      ]
    }
  ]
}