{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt2nTxIs19OxaF/iDGbbhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Ikhwan-Fathulloh/Generative-Adversarial-Network-GAN/blob/main/avb_pytorch_mse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH_kYYmPM8rm",
        "outputId": "eb2126fd-d24b-4b0a-9db6-ab93582dd03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter-0; ELBO: -0.1183; T_loss: -1.392\n",
            "Iter-1000; ELBO: 0.3879; T_loss: -2.061\n",
            "Iter-2000; ELBO: 0.005128; T_loss: -1.534\n",
            "Iter-3000; ELBO: -0.03213; T_loss: -1.426\n",
            "Iter-4000; ELBO: -0.1108; T_loss: -1.443\n",
            "Iter-5000; ELBO: -0.2286; T_loss: -1.259\n",
            "Iter-6000; ELBO: -19.61; T_loss: -0.001279\n",
            "Iter-7000; ELBO: 0.01488; T_loss: -1.498\n",
            "Iter-8000; ELBO: 0.0259; T_loss: -1.466\n",
            "Iter-9000; ELBO: 0.009234; T_loss: -1.586\n",
            "Iter-10000; ELBO: -0.1148; T_loss: -1.356\n",
            "Iter-11000; ELBO: -0.1378; T_loss: -1.354\n",
            "Iter-12000; ELBO: 0.006345; T_loss: -1.493\n",
            "Iter-13000; ELBO: 0.07863; T_loss: -1.514\n",
            "Iter-14000; ELBO: 0.0828; T_loss: -1.457\n",
            "Iter-15000; ELBO: -0.01851; T_loss: -1.44\n",
            "Iter-16000; ELBO: -0.02504; T_loss: -1.462\n",
            "Iter-17000; ELBO: -0.07535; T_loss: -1.409\n",
            "Iter-18000; ELBO: -0.09085; T_loss: -1.398\n",
            "Iter-19000; ELBO: 0.02439; T_loss: -1.441\n",
            "Iter-20000; ELBO: -0.04885; T_loss: -1.381\n",
            "Iter-21000; ELBO: -0.0758; T_loss: -1.373\n",
            "Iter-22000; ELBO: -0.04425; T_loss: -1.374\n",
            "Iter-23000; ELBO: -0.1828; T_loss: -1.382\n",
            "Iter-24000; ELBO: -0.1262; T_loss: -1.299\n",
            "Iter-25000; ELBO: -0.0672; T_loss: -1.441\n",
            "Iter-26000; ELBO: -0.3886; T_loss: -1.102\n",
            "Iter-27000; ELBO: 0.6674; T_loss: -2.933\n",
            "Iter-28000; ELBO: -0.3136; T_loss: -1.379\n",
            "Iter-29000; ELBO: -0.5717; T_loss: -1.438\n",
            "Iter-30000; ELBO: -0.4768; T_loss: -1.052\n",
            "Iter-31000; ELBO: -1.154; T_loss: -0.8206\n",
            "Iter-32000; ELBO: -0.6923; T_loss: -0.9465\n",
            "Iter-33000; ELBO: -0.4813; T_loss: -0.8968\n",
            "Iter-34000; ELBO: -0.2305; T_loss: -1.302\n",
            "Iter-35000; ELBO: -0.4139; T_loss: -1.083\n",
            "Iter-36000; ELBO: -0.861; T_loss: -1.025\n",
            "Iter-37000; ELBO: -0.3543; T_loss: -1.125\n",
            "Iter-38000; ELBO: -0.4844; T_loss: -1.178\n",
            "Iter-39000; ELBO: -0.4972; T_loss: -1.217\n",
            "Iter-40000; ELBO: -0.7084; T_loss: -1.08\n",
            "Iter-41000; ELBO: -0.8333; T_loss: -0.8706\n",
            "Iter-42000; ELBO: -0.2375; T_loss: -1.218\n",
            "Iter-43000; ELBO: -0.5959; T_loss: -1.168\n",
            "Iter-44000; ELBO: -0.4575; T_loss: -1.116\n",
            "Iter-45000; ELBO: -0.3895; T_loss: -1.14\n",
            "Iter-46000; ELBO: -0.2069; T_loss: -1.357\n",
            "Iter-47000; ELBO: -0.2469; T_loss: -1.327\n",
            "Iter-48000; ELBO: 0.05627; T_loss: -1.459\n",
            "Iter-49000; ELBO: -0.6377; T_loss: -1.256\n",
            "Iter-50000; ELBO: -0.2555; T_loss: -1.127\n",
            "Iter-51000; ELBO: -0.1593; T_loss: -1.356\n",
            "Iter-52000; ELBO: -0.09185; T_loss: -1.606\n",
            "Iter-53000; ELBO: -0.5911; T_loss: -1.278\n",
            "Iter-54000; ELBO: -0.09709; T_loss: -1.269\n",
            "Iter-55000; ELBO: -0.341; T_loss: -1.351\n",
            "Iter-56000; ELBO: -0.3235; T_loss: -1.206\n",
            "Iter-57000; ELBO: 0.1359; T_loss: -1.684\n",
            "Iter-58000; ELBO: -0.297; T_loss: -1.302\n",
            "Iter-59000; ELBO: -0.2088; T_loss: -1.207\n",
            "Iter-60000; ELBO: -0.1726; T_loss: -1.412\n",
            "Iter-61000; ELBO: -0.09363; T_loss: -1.302\n",
            "Iter-62000; ELBO: 0.158; T_loss: -1.559\n",
            "Iter-63000; ELBO: 0.04613; T_loss: -1.556\n",
            "Iter-64000; ELBO: -0.1474; T_loss: -1.306\n",
            "Iter-65000; ELBO: -0.1006; T_loss: -1.328\n",
            "Iter-66000; ELBO: -0.1683; T_loss: -1.357\n",
            "Iter-67000; ELBO: -0.1159; T_loss: -1.395\n",
            "Iter-68000; ELBO: 0.05012; T_loss: -1.513\n",
            "Iter-69000; ELBO: -0.2496; T_loss: -1.277\n",
            "Iter-70000; ELBO: -0.3243; T_loss: -1.356\n",
            "Iter-71000; ELBO: 0.02061; T_loss: -1.467\n",
            "Iter-72000; ELBO: -0.09283; T_loss: -1.462\n",
            "Iter-73000; ELBO: -0.03695; T_loss: -1.462\n",
            "Iter-74000; ELBO: 0.02123; T_loss: -1.524\n",
            "Iter-75000; ELBO: 0.005477; T_loss: -1.553\n",
            "Iter-76000; ELBO: -0.3928; T_loss: -1.262\n",
            "Iter-77000; ELBO: -0.1983; T_loss: -1.382\n",
            "Iter-78000; ELBO: -0.2941; T_loss: -1.296\n",
            "Iter-79000; ELBO: -0.06489; T_loss: -1.401\n",
            "Iter-80000; ELBO: -0.3054; T_loss: -1.272\n",
            "Iter-81000; ELBO: -0.3812; T_loss: -1.203\n",
            "Iter-82000; ELBO: 0.02205; T_loss: -1.445\n",
            "Iter-83000; ELBO: -0.1189; T_loss: -1.339\n",
            "Iter-84000; ELBO: -0.1221; T_loss: -1.454\n",
            "Iter-85000; ELBO: 0.02038; T_loss: -1.494\n",
            "Iter-86000; ELBO: -0.106; T_loss: -1.399\n",
            "Iter-87000; ELBO: -0.05187; T_loss: -1.414\n",
            "Iter-88000; ELBO: -0.382; T_loss: -1.176\n",
            "Iter-89000; ELBO: -0.4748; T_loss: -1.289\n",
            "Iter-90000; ELBO: -0.07035; T_loss: -1.389\n",
            "Iter-91000; ELBO: -0.2982; T_loss: -1.353\n",
            "Iter-92000; ELBO: -0.1906; T_loss: -1.297\n",
            "Iter-93000; ELBO: -0.1399; T_loss: -1.433\n",
            "Iter-94000; ELBO: -0.1348; T_loss: -1.216\n",
            "Iter-95000; ELBO: -0.2179; T_loss: -1.262\n",
            "Iter-96000; ELBO: -0.002121; T_loss: -1.435\n",
            "Iter-97000; ELBO: -0.3398; T_loss: -1.398\n",
            "Iter-98000; ELBO: -0.05958; T_loss: -1.441\n",
            "Iter-99000; ELBO: -0.1926; T_loss: -1.379\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "mnist = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "\n",
        "# Normalize the data to [0, 1] range\n",
        "mnist.data = mnist.data.float() / 255.0\n",
        "\n",
        "# Parameters\n",
        "mb_size = 32\n",
        "z_dim = 5\n",
        "X_dim = mnist.data.size(1) * mnist.data.size(2)  # Flattened image dimensions\n",
        "h_dim = 128\n",
        "lr = 1e-3\n",
        "\n",
        "# Create noise dimension\n",
        "eps_dim = 10  # Dimension of the noise vector\n",
        "\n",
        "# Encoder: q(z|x,eps)\n",
        "Q = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + eps_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, z_dim)\n",
        ")\n",
        "\n",
        "# Decoder: p(x|z)\n",
        "P = torch.nn.Sequential(\n",
        "    torch.nn.Linear(z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, X_dim),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Discriminator: T(X, z)\n",
        "T = torch.nn.Sequential(\n",
        "    torch.nn.Linear(X_dim + z_dim, h_dim),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(h_dim, 1)\n",
        ")\n",
        "\n",
        "def reset_grad():\n",
        "    Q.zero_grad()\n",
        "    P.zero_grad()\n",
        "    T.zero_grad()\n",
        "\n",
        "\n",
        "def sample_X(size):\n",
        "    indices = np.random.randint(0, len(mnist), size)\n",
        "    X = mnist.data[indices].view(size, -1).float()\n",
        "    return Variable(X)\n",
        "\n",
        "\n",
        "# Optimizers\n",
        "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
        "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
        "T_solver = optim.Adam(T.parameters(), lr=lr)\n",
        "\n",
        "# Initialize counter\n",
        "cnt = 0\n",
        "\"\"\"1000000\"\"\"\n",
        "\n",
        "# Your training loop goes here\n",
        "for it in range(100000):\n",
        "    X = sample_X(mb_size)\n",
        "    eps = Variable(torch.randn(mb_size, eps_dim))\n",
        "    z = Variable(torch.randn(mb_size, z_dim))\n",
        "\n",
        "    # Optimize VAE\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    X_sample = P(z_sample)\n",
        "    T_sample = T(torch.cat([X, z_sample], 1))\n",
        "\n",
        "    disc = torch.mean(-T_sample)\n",
        "    loglike = -nn.MSELoss()(X_sample, X) # Use BCELoss for binary cross-entropy\n",
        "\n",
        "    elbo = -(disc + loglike)\n",
        "\n",
        "    elbo.backward()\n",
        "    Q_solver.step()\n",
        "    P_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Discriminator T(X, z)\n",
        "    z_sample = Q(torch.cat([X, eps], 1))\n",
        "    T_q = nn.Sigmoid()(T(torch.cat([X, z_sample], 1)))\n",
        "    T_prior = nn.Sigmoid()(T(torch.cat([X, z], 1)))\n",
        "\n",
        "    T_loss = -torch.mean(torch.log(T_q) + torch.log(1. - T_prior))\n",
        "\n",
        "    T_loss.backward()\n",
        "    T_solver.step()\n",
        "    reset_grad()\n",
        "\n",
        "    # Print and plot every now and then\n",
        "    if it % 1000 == 0:\n",
        "        print('Iter-{}; ELBO: {:.4}; T_loss: {:.4}'\n",
        "              .format(it, -elbo.item(), -T_loss.item()))\n",
        "\n",
        "        samples = P(z).data.numpy()[:16]\n",
        "\n",
        "        fig = plt.figure(figsize=(4, 4))\n",
        "        gs = gridspec.GridSpec(4, 4)\n",
        "        gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for i, sample in enumerate(samples):\n",
        "            ax = plt.subplot(gs[i])\n",
        "            plt.axis('off')\n",
        "            ax.set_xticklabels([])\n",
        "            ax.set_yticklabels([])\n",
        "            ax.set_aspect('equal')\n",
        "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
        "\n",
        "        if not os.path.exists('out/'):\n",
        "            os.makedirs('out/')\n",
        "\n",
        "        plt.savefig('out/{}.png'\n",
        "                    .format(str(cnt).zfill(3)), bbox_inches='tight')\n",
        "        cnt += 1\n",
        "        plt.close(fig)"
      ]
    }
  ]
}